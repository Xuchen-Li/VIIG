<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-HJJPG4QHJ9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-HJJPG4QHJ9');
  </script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="favicon.webp" type="image/x-icon">
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Demos - Visual Intelligence Interest Group (VIIG)</title>
  <link rel="stylesheet" href="css/stanford.css">

  <style type="text/css">
    p {
      text-align: justify;
    }

    table {
      margin-left: auto;
      margin-right: auto;
    }

    .container {
      width: 100%;
    }

    .hamburger {
      position: relative;
      cursor: pointer;
      z-index: 1000;
    }

    #navigation {
      position: absolute;
      top: 100%;
      left: -40px;
      width: 200%;
      box-sizing: border-box;
      background-color: rgba(255, 255, 255);
      padding: 0;
      margin: 0;
      list-style: none;
      display: flex;
      flex-direction: column;
      align-items: center;
      opacity: 0;
      visibility: hidden;
      transition: opacity 0.3s, visibility 0.3s;
      box-shadow: none;
      border-radius: 10px;
    }

    #navigation.show-menu {
      opacity: 1;
      visibility: visible;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
    }

    .header-title img {
      border-radius: 10px;
    }

    .menu-item-about.active a,
    .menu-item-people.active a,
    .menu-item-publications.active a,
    .menu-item-software.active a,
    .menu-item-others.active a {
      border-radius: 10px;
    }

    #main-menu ul li a {
      display: block;
      padding: 10px 15px;
      border-radius: 10px;
      transition: background-color 0.3s, color 0.3s, border-radius 0.3s;
    }

    #main-menu ul li a:hover {
      border-radius: 10px;
    }

    #main-menu ul li a span {
      display: inline-block;
      transition: background-color 0.3s, color 0.3s, border-radius 0.3s;
    }

    #main-menu ul li a span.active {
      background-color: #e0e0e0;
      color: #000;
      border-radius: 10px;
    }

    video {
      width: 1000;
      height: auto;
      border-radius: 5px;
    }

    @media (max-width: 768px) {
      p {
        font-size: calc(3vw);
      }

      h3 {
        font-size: calc(4vw);
      }

      video {
        width: 100%;
        height: auto;
        border-radius: 5px;
      }
    }
  </style>
</head>

<body class='page page-about'>
  <div class="wrapper">
    <div class='header'>
      <div class="container">
        <h3 class="header-title">
          <a href="./index.html"><img src="./grouplogo.webp" style="max-width: 50%"></a>
        </h3>
        <div id="main-menu" class="main-menu">
          <ul>
            <li class="menu-item-about">
              <a href="./index.html">
                <span>Home</span>
              </a>
            </li>
            <li class="menu-item-people">
              <a href="./people.html">
                <span>People</span>
              </a>
            </li>
            <li class="menu-item-publications">
              <a href="./publication.html">
                <span>Publication</span>
              </a>
            </li>
            <li class="menu-item-software">
              <a href="./research.html">
                <span>Research</span>
              </a>
            </li>
            <li class="menu-item-software  active">
              <a href="./info.html">
                <span>Demos</span>
              </a>
            </li>
          </ul>
        </div>
        <div class="hamburger hamburger--slider" tabindex="0" aria-label="Menu" role="button"
          aria-controls="navigation">
          <div class="hamburger-box">
            <div class="hamburger-inner"></div>
          </div>
          <nav id="navigation">
            <a href="./index.html">
              <span>Home</span>
            </a>
            <a href="./people.html">
              <span>People</span>
            </a>
            <a href="./publication.html">
              <span>Publication</span>
            </a>
            <a href="./research.html">
              <span>Research</span>
            </a>
            <a href="./info.html">
              <span>Demos</span>
            </a>
          </nav>
        </div>
      </div>
    </div>

    <div class="container mt-2">
      <div>
        <ul>
          <ul>
            <h3>
              <strong>GOT-10k: A Large High-diversity Benchmark and Evaluation Platform for Single Object Tracking
              </strong>
            </h3>
            <p>
              Visual Object Tracking & Evaluation Technology & Large High-diversity Benchmark
            </p>
            <p>
              GOT-10k is constructed to evaluate the generalization ability of trackers on unseen object classes and
              motion patterns. The platform provides a high-quality video trajectory dataset containing 10,000 video
              segments, 563 object classes, 87 motion patterns, and 1.5 million tight annotations.
            </p>
            <p>
              GOT-10k is the supporting platform for a research accepted by IEEE TPAMI 2019. As of Feb. 2024, the
              platform has received 3.24M+ page views, 6k+ downloads, 18k+ trackers from 160+ countries and regions
              worldwide.
            </p>
          </ul>
        </ul>
        <table>
          <tr>
            <td>
              <video width="1000" controls="true" controlslist="nodownload">
                <source src="img/demos/got-10k.mp4" type="video/mp4">
                </source>
              </video>
            </td>
          </tr>
        </table>
      </div>
      <hr>
      <div>
        <ul>
          <ul>
            <h3><strong>VideoCube: A Large-scale Multi-dimensional Global Instance Tracking Intelligent Evaluation
                Platform</strong>
            </h3>
            <p>
              Visual Object Tracking & Large-scale Benchmark Construction & Intelligent Evaluation Technology
            </p>
            <p>
              This work builds on the concept of human-like modeling and expands the definition of single object
              tracking (SOT) task. It presents a new task called global instance tracking (GIT). This work builds a
              large-scale, multi-dimensional global instance tracking task intelligent evaluation platform called
              VideoCube.
            </p>
            <p>
              VideoCube is the supporting platform for research accepted by IEEE TPAMI 2022. As of Feb. 2024, the
              platform has received 315k+ page views, 1k+ downloads, 400+ trackers from 130+ countries and regions
              worldwide.
            </p>
          </ul>
        </ul>
        <table>
          <tr>
            <td>
              <video width="1000" controls="true" controlslist="nodownload">
                <source src="img/demos/videocube.mp4" type="video/mp4">
                </source>
              </video>
            </td>
          </tr>
        </table>
      </div>
      <hr>
      <div>
        <ul>
          <ul>
            <h3><strong>MGIT: A Multi-modal Global Instance Tracking Benchmark Based on Hierarchical Semantic
                Framework</strong></h3>
            <p>
              Visual Language Tracking & Long Video Understanding and Reasoning & Hierarchical Semantic Information
              Annotation
            </p>
            <p>
              This work extends the GIT task and the VideoCube benchmark by constructing a multi-modal benchmark called
              MGIT. The MGIT benchmark is designed to capture the complex video narrative relationships and fully
              encompass the intricate spatio temporal and causal connections illustrated in long videos.
            </p>
            <p>
              MGIT is the supporting platform for research accepted by NeurIPS 2023. As of Feb. 2024, the platform has
              received 315k+ page views, 1k+ downloads, 400+ trackers from 130+ countries and regions worldwide.
            </p>
          </ul>
        </ul>
        <table>
          <tr>
            <td>
              <video width="1000" controls="true" controlslist="nodownload">
                <source src="img/demos/mgit.mp4" type="video/mp4">
                </source>
              </video>
            </td>
          </tr>
        </table>
      </div>
      <hr>
      <div>
        <ul>
          <ul>
            <h3><strong>BioDrone: A Bionic Drone-based Single Object Tracking Benchmark for Robust Vision</strong></h3>
            <p>
              Visual Object Tracking & Drone-based Tracking & Robust Visual Research
            </p>
            <p>
              BioDrone is the first bionic drone-based SOT benchmark, it features videos captured from a flapping-wing
              UAV system with a major camera shake due to its aerodynamics. BioDrone highlights the tracking of tiny
              targets with drastic changes between consecutive frames, providing a new robust vision benchmark for SOT.
            </p>
            <p>
              BioDrone is the supporting platform for research accepted by IJCV 2023 and the organization of the 3rd
              High-Speed Low-Power Visual Understanding Challenge as competition data.
            </p>
          </ul>
        </ul>
        <table>
          <tr>
            <td>
              <video width="1000" controls="true" controlslist="nodownload">
                <source src="img/demos/biodrone.mp4" type="video/mp4">
                </source>
              </video>
            </td>
          </tr>
        </table>
      </div>
      <hr>
      <div>
        <ul>
          <ul>
            <h3><strong>AWCV-100k: A Unconstrained Air-writing Benchmark for Real-World Applications</strong></h3>
            <p>
              Air-writing Technique & Benchmark Construction & Human-machine Interaction
            </p>
            <p>
              The AWCV-100k dataset comprises 8.8 million video frames, encompassing diverse environmental settings and
              lighting conditions. It provides comprehensive coverage of 3,755 Chinese characters from the GB2312-80
              character set, establishing it as the most extensive and comprehensive air-writing video dataset currently
              accessible.
            </p>
            <p>
              AWCV-100k is the supporting platform for research accepted by IEEE TCSVT 2024. Subsequent work will be
              conducted based on this benchmark for HCI technology research.
            </p>
          </ul>
        </ul>
        <table>
          <tr>
            <td>
              <video width="1000" controls="true" controlslist="nodownload">
                <source src="img/demos/awcv.mp4" type="video/mp4">
                </source>
              </video>
            </td>
          </tr>
        </table>
      </div>
    </div>
  </div>

  <script>
    document.addEventListener('DOMContentLoaded', function () {
      var menuButton = document.querySelector('.hamburger');
      var navigation = document.getElementById('navigation');

      menuButton.addEventListener('click', function () {
        navigation.classList.toggle('show-menu');
      });
    });
  </script>
  <script src="js/jquery-3.4.1.slim.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.15.0/umd/popper.min.js"
    integrity="sha256-fTuUgtT7O2rqoImwjrhDgbXTKUwyxxujIMRIK7TbuNU=" crossorigin="anonymous"></script>
</body>

</html>